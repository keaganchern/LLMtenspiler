{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries and setup\n",
    "import google.generativeai as genai\n",
    "import sys\n",
    "import re\n",
    "import uuid\n",
    "from textwrap import dedent\n",
    "from typing import Dict\n",
    "from typing import List as pyList\n",
    "from typing import Optional\n",
    "from typing import Tuple as pyTuple\n",
    "from typing import Type, Union, cast, get_args\n",
    "\n",
    "from mypy import build\n",
    "from mypy.defaults import PYTHON3_VERSION\n",
    "from mypy.modulefinder import BuildSource\n",
    "from mypy.nodes import (\n",
    "    AssignmentStmt,\n",
    "    Block,\n",
    "    CallExpr,\n",
    "    ComparisonExpr,\n",
    "    ConditionalExpr,\n",
    "    FuncDef,\n",
    "    IndexExpr,\n",
    "    IntExpr,\n",
    "    LambdaExpr,\n",
    "    ListExpr,\n",
    "    MemberExpr,\n",
    "    MypyFile,\n",
    "    NameExpr,\n",
    "    Node,\n",
    "    OpExpr,\n",
    "    ReturnStmt,\n",
    "    SliceExpr,\n",
    ")\n",
    "from mypy.options import Options\n",
    "from mypy.types import AnyType, CallableType, Instance\n",
    "from mypy.types import Type as MypyType\n",
    "from mypy.types import TypeList, UnboundType\n",
    "\n",
    "from metalift.ir import (\n",
    "    Add,\n",
    "    And,\n",
    "    Bool,\n",
    "    Div,\n",
    "    Eq,\n",
    "    Expr,\n",
    "    Fn,\n",
    "    FnDeclRecursive,\n",
    "    Ge,\n",
    "    Gt,\n",
    "    Int,\n",
    "    Le,\n",
    "    List,\n",
    "    Lt,\n",
    "    Mod,\n",
    "    Mul,\n",
    "    Object,\n",
    "    ObjectT,\n",
    "    Or,\n",
    "    Sub,\n",
    "    Matrix,\n",
    "    call,\n",
    "    create_object,\n",
    "    fn_decl_recursive,\n",
    "    is_fn_decl_type,\n",
    "    is_list_type,\n",
    "    is_nested_list_type,\n",
    "    ite,\n",
    "    Not\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "#Add project files to be imported\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.join(script_dir, '..')\n",
    "\n",
    "sys.path.append(os.path.abspath(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: Your task is to rewrite the given C benchmark code in Python. You need to use only the set of \n",
      "provided functions and constants to achieve this. The rewritten program should be semantically \n",
      "equivalent to the benchmark.\n",
      "#Instructions\n",
      "1. The rewritten program should just be a single return statement of the form return_var = provided_function()\n",
      "2. Do not use for/while loops for rewriting the function\n",
      "3. Inline all the expressions, Do not use intermediate variables\n",
      "4. The rewritten program should only use built-in Python functions and the provided functions and constants\n",
      "\n",
      "----------------------------Defined Functions---------------------------- \n",
      "from typing import Callable, List\n",
      "\n",
      "def matrix_elemwise_add(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_add(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_add(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "def matrix_elemwise_sub(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_sub(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_sub(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "\n",
      "def matrix_elemwise_mul(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_mul(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_mul(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "\n",
      "def matrix_elemwise_div(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_div(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_div(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "def matrix_scalar_add(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_add(a, matrix_x[0]), *matrix_scalar_add(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def matrix_scalar_sub(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_sub(a, matrix_x[0]), *matrix_scalar_sub(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def matrix_scalar_mul(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_mul(a, matrix_x[0]), *matrix_scalar_mul(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "\n",
      "def matrix_scalar_div(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_div(a, matrix_x[0]), *matrix_scalar_div(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def scalar_matrix_div(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [scalar_vec_div(a, matrix_x[0]), *scalar_matrix_div(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def scalar_matrix_sub(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [scalar_vec_sub(a, matrix_x[0]), *scalar_matrix_sub(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def scalar_vec_sub(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(a - x[0]), *scalar_vec_sub(a, x[1:])]\n",
      "\n",
      "\n",
      "def scalar_vec_div(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(a // x[0]), *scalar_vec_div(a, x[1:])]\n",
      "\n",
      "\n",
      "def vec_elemwise_add(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [x[0] + y[0], *vec_elemwise_add(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "def vec_elemwise_sub(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [(x[0] - y[0]), *vec_elemwise_sub(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "def vec_elemwise_mul(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [x[0] * y[0], *vec_elemwise_mul(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "def vec_elemwise_div(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [(x[0] // y[0]), *vec_elemwise_div(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "def vec_scalar_add(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [a + x[0], *vec_scalar_add(a, x[1:])]\n",
      "\n",
      "def vec_scalar_sub(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(x[0] - a), *vec_scalar_sub(a, x[1:])]\n",
      "\n",
      "\n",
      "def vec_scalar_mul(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [a * x[0], *vec_scalar_mul(a, x[1:])]\n",
      "\n",
      "\n",
      "def vec_scalar_div(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(x[0] // a), *vec_scalar_div(a, x[1:])]\n",
      "\n",
      "\n",
      "----------------------------Function to Rewrite----------------------------\n",
      "\n",
      "\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <unistd.h>\n",
      "#include <string.h>\n",
      "#include <math.h>\n",
      "\n",
      "\n",
      "#include <polybench.h>\n",
      "\n",
      "\n",
      "#include \"2mm.h\"\n",
      "\n",
      "\n",
      "\n",
      "static\n",
      "void init_array(int ni, int nj, int nk, int nl,\n",
      "\t\tDATA_TYPE *alpha,\n",
      "\t\tDATA_TYPE *beta,\n",
      "\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(C,NJ,NL,nj,nl),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n",
      "{\n",
      "  int i, j;\n",
      "\n",
      "  *alpha = 1.5;\n",
      "  *beta = 1.2;\n",
      "  for (i = 0; i < ni; i++)\n",
      "    for (j = 0; j < nk; j++)\n",
      "      A[i][j] = (DATA_TYPE) ((i*j+1) % ni) / ni;\n",
      "  for (i = 0; i < nk; i++)\n",
      "    for (j = 0; j < nj; j++)\n",
      "      B[i][j] = (DATA_TYPE) (i*(j+1) % nj) / nj;\n",
      "  for (i = 0; i < nj; i++)\n",
      "    for (j = 0; j < nl; j++)\n",
      "      C[i][j] = (DATA_TYPE) ((i*(j+3)+1) % nl) / nl;\n",
      "  for (i = 0; i < ni; i++)\n",
      "    for (j = 0; j < nl; j++)\n",
      "      D[i][j] = (DATA_TYPE) (i*(j+2) % nk) / nk;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "static\n",
      "void print_array(int ni, int nl,\n",
      "\t\t DATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n",
      "{\n",
      "  int i, j;\n",
      "\n",
      "  POLYBENCH_DUMP_START;\n",
      "  POLYBENCH_DUMP_BEGIN(\"D\");\n",
      "  for (i = 0; i < ni; i++)\n",
      "    for (j = 0; j < nl; j++) {\n",
      "\tif ((i * ni + j) % 20 == 0) fprintf (POLYBENCH_DUMP_TARGET, \"\\n\");\n",
      "\tfprintf (POLYBENCH_DUMP_TARGET, DATA_PRINTF_MODIFIER, D[i][j]);\n",
      "    }\n",
      "  POLYBENCH_DUMP_END(\"D\");\n",
      "  POLYBENCH_DUMP_FINISH;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "static\n",
      "void kernel_2mm(int ni, int nj, int nk, int nl,\n",
      "\t\tDATA_TYPE alpha,\n",
      "\t\tDATA_TYPE beta,\n",
      "\t\tDATA_TYPE POLYBENCH_2D(tmp,NI,NJ,ni,nj),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(C,NJ,NL,nj,nl),\n",
      "\t\tDATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n",
      "{\n",
      "  int i, j, k;\n",
      "\n",
      "#pragma scop\n",
      "  \n",
      "  for (i = 0; i < _PB_NI; i++)\n",
      "    for (j = 0; j < _PB_NJ; j++)\n",
      "      {\n",
      "\ttmp[i][j] = SCALAR_VAL(0.0);\n",
      "\tfor (k = 0; k < _PB_NK; ++k)\n",
      "\t  tmp[i][j] += alpha * A[i][k] * B[k][j];\n",
      "      }\n",
      "  for (i = 0; i < _PB_NI; i++)\n",
      "    for (j = 0; j < _PB_NL; j++)\n",
      "      {\n",
      "\tD[i][j] *= beta;\n",
      "\tfor (k = 0; k < _PB_NJ; ++k)\n",
      "\t  D[i][j] += tmp[i][k] * C[k][j];\n",
      "      }\n",
      "#pragma endscop\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "int main(int argc, char** argv)\n",
      "{\n",
      "  \n",
      "  int ni = NI;\n",
      "  int nj = NJ;\n",
      "  int nk = NK;\n",
      "  int nl = NL;\n",
      "\n",
      "  \n",
      "  DATA_TYPE alpha;\n",
      "  DATA_TYPE beta;\n",
      "  POLYBENCH_2D_ARRAY_DECL(tmp,DATA_TYPE,NI,NJ,ni,nj);\n",
      "  POLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NK,ni,nk);\n",
      "  POLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NK,NJ,nk,nj);\n",
      "  POLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NJ,NL,nj,nl);\n",
      "  POLYBENCH_2D_ARRAY_DECL(D,DATA_TYPE,NI,NL,ni,nl);\n",
      "\n",
      "  \n",
      "  init_array (ni, nj, nk, nl, &alpha, &beta,\n",
      "\t      POLYBENCH_ARRAY(A),\n",
      "\t      POLYBENCH_ARRAY(B),\n",
      "\t      POLYBENCH_ARRAY(C),\n",
      "\t      POLYBENCH_ARRAY(D));\n",
      "\n",
      "  \n",
      "  polybench_start_instruments;\n",
      "\n",
      "  \n",
      "  kernel_2mm (ni, nj, nk, nl,\n",
      "\t      alpha, beta,\n",
      "\t      POLYBENCH_ARRAY(tmp),\n",
      "\t      POLYBENCH_ARRAY(A),\n",
      "\t      POLYBENCH_ARRAY(B),\n",
      "\t      POLYBENCH_ARRAY(C),\n",
      "\t      POLYBENCH_ARRAY(D));\n",
      "\n",
      "  \n",
      "  polybench_stop_instruments;\n",
      "  polybench_print_instruments;\n",
      "\n",
      "  \n",
      "  polybench_prevent_dce(print_array(ni, nl,  POLYBENCH_ARRAY(D)));\n",
      "\n",
      "  \n",
      "  POLYBENCH_FREE_ARRAY(tmp);\n",
      "  POLYBENCH_FREE_ARRAY(A);\n",
      "  POLYBENCH_FREE_ARRAY(B);\n",
      "  POLYBENCH_FREE_ARRAY(C);\n",
      "  POLYBENCH_FREE_ARRAY(D);\n",
      "\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#ifndef POLYBENCH_H\n",
      "# define POLYBENCH_H\n",
      "\n",
      "# include <stdlib.h>\n",
      "\n",
      "\n",
      "# ifndef POLYBENCH_PADDING_FACTOR\n",
      "\n",
      "#  define POLYBENCH_PADDING_FACTOR 0\n",
      "# endif\n",
      "\n",
      "\n",
      "# ifndef POLYBENCH_INTER_ARRAY_PADDING_FACTOR\n",
      "\n",
      "#  define POLYBENCH_INTER_ARRAY_PADDING_FACTOR 0\n",
      "#  undef POLYBENCH_ENABLE_INTARRAY_PAD\n",
      "# else\n",
      "#  define POLYBENCH_ENABLE_INTARRAY_PAD\n",
      "# endif\n",
      "\n",
      "\n",
      "\n",
      "# ifdef POLYBENCH_USE_C99_PROTO\n",
      "#  define POLYBENCH_C99_SELECT(x,y) y\n",
      "# else\n",
      "\n",
      "#  define POLYBENCH_C99_SELECT(x,y) x\n",
      "# endif\n",
      "\n",
      "\n",
      "\n",
      "# ifdef POLYBENCH_USE_SCALAR_LB\n",
      "#  define POLYBENCH_LOOP_BOUND(x,y) x\n",
      "# else\n",
      "\n",
      "#  define POLYBENCH_LOOP_BOUND(x,y) y\n",
      "# endif\n",
      "\n",
      "\n",
      "# ifdef POLYBENCH_USE_RESTRICT\n",
      "#  define POLYBENCH_RESTRICT restrict\n",
      "# else\n",
      "\n",
      "#  define POLYBENCH_RESTRICT\n",
      "# endif\n",
      "\n",
      "\n",
      "# ifndef POLYBENCH_STACK_ARRAYS\n",
      "#  define POLYBENCH_ARRAY(x) *x\n",
      "#  ifdef POLYBENCH_ENABLE_INTARRAY_PAD\n",
      "#   define POLYBENCH_FREE_ARRAY(x) polybench_free_data((void*)x);\n",
      "#  else\n",
      "#   define POLYBENCH_FREE_ARRAY(x) free((void*)x);\n",
      "#  endif\n",
      "#  define POLYBENCH_DECL_VAR(x) (*x)\n",
      "# else\n",
      "#  define POLYBENCH_ARRAY(x) x\n",
      "#  define POLYBENCH_FREE_ARRAY(x)\n",
      "#  define POLYBENCH_DECL_VAR(x) x\n",
      "# endif\n",
      "\n",
      "# define POLYBENCH_1D(var, dim1,ddim1) var[POLYBENCH_RESTRICT POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_2D(var, dim1, dim2, ddim1, ddim2) var[POLYBENCH_RESTRICT POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_3D(var, dim1, dim2, dim3, ddim1, ddim2, ddim3) var[POLYBENCH_RESTRICT POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim3,ddim3) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_4D(var, dim1, dim2, dim3, dim4, ddim1, ddim2, ddim3, ddim4) var[POLYBENCH_RESTRICT POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim3,ddim3) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim4,ddim4) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_5D(var, dim1, dim2, dim3, dim4, dim5, ddim1, ddim2, ddim3, ddim4, ddim5) var[POLYBENCH_RESTRICT POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim3,ddim3) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim4,ddim4) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim5,ddim5) + POLYBENCH_PADDING_FACTOR]\n",
      "\n",
      "# define POLYBENCH_1D_F(var, dim1,ddim1) var[POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_2D_F(var, dim1, dim2, ddim1, ddim2) var[POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_3D_F(var, dim1, dim2, dim3, ddim1, ddim2, ddim3) var[POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim3,ddim3) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_4D_F(var, dim1, dim2, dim3, dim4, ddim1, ddim2, ddim3, ddim4) var[POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim3,ddim3) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim4,ddim4) + POLYBENCH_PADDING_FACTOR]\n",
      "# define POLYBENCH_5D_F(var, dim1, dim2, dim3, dim4, dim5, ddim1, ddim2, ddim3, ddim4, ddim5) var[POLYBENCH_C99_SELECT(dim1,ddim1) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim2,ddim2) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim3,ddim3) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim4,ddim4) + POLYBENCH_PADDING_FACTOR][POLYBENCH_C99_SELECT(dim5,ddim5) + POLYBENCH_PADDING_FACTOR]\n",
      "\n",
      "\n",
      "\n",
      "# define POLYBENCH_ALLOC_1D_ARRAY(n1, type)\t\\\n",
      "  (type(*)[n1 + POLYBENCH_PADDING_FACTOR])polybench_alloc_data (n1 + POLYBENCH_PADDING_FACTOR, sizeof(type))\n",
      "# define POLYBENCH_ALLOC_2D_ARRAY(n1, n2, type)\t\t\\\n",
      "  (type(*)[n1 + POLYBENCH_PADDING_FACTOR][n2 + POLYBENCH_PADDING_FACTOR])polybench_alloc_data ((n1 + POLYBENCH_PADDING_FACTOR) * (n2 + POLYBENCH_PADDING_FACTOR), sizeof(type))\n",
      "# define POLYBENCH_ALLOC_3D_ARRAY(n1, n2, n3, type)\t\t\\\n",
      "  (type(*)[n1 + POLYBENCH_PADDING_FACTOR][n2 + POLYBENCH_PADDING_FACTOR][n3 + POLYBENCH_PADDING_FACTOR])polybench_alloc_data ((n1 + POLYBENCH_PADDING_FACTOR) * (n2 + POLYBENCH_PADDING_FACTOR) * (n3 + POLYBENCH_PADDING_FACTOR), sizeof(type))\n",
      "# define POLYBENCH_ALLOC_4D_ARRAY(n1, n2, n3, n4, type)\t\t\t\\\n",
      "  (type(*)[n1 + POLYBENCH_PADDING_FACTOR][n2 + POLYBENCH_PADDING_FACTOR][n3 + POLYBENCH_PADDING_FACTOR][n4 + POLYBENCH_PADDING_FACTOR])polybench_alloc_data ((n1 + POLYBENCH_PADDING_FACTOR) * (n2 + POLYBENCH_PADDING_FACTOR) * (n3 + POLYBENCH_PADDING_FACTOR) * (n4 + POLYBENCH_PADDING_FACTOR), sizeof(type))\n",
      "# define POLYBENCH_ALLOC_5D_ARRAY(n1, n2, n3, n4, n5, type)\t\t\\\n",
      "  (type(*)[n1 + POLYBENCH_PADDING_FACTOR][n2 + POLYBENCH_PADDING_FACTOR][n3 + POLYBENCH_PADDING_FACTOR][n4 + POLYBENCH_PADDING_FACTOR][n5 + POLYBENCH_PADDING_FACTOR])polybench_alloc_data ((n1 + POLYBENCH_PADDING_FACTOR) * (n2 + POLYBENCH_PADDING_FACTOR) * (n3 + POLYBENCH_PADDING_FACTOR) * (n4 + POLYBENCH_PADDING_FACTOR) * (n5 + POLYBENCH_PADDING_FACTOR), sizeof(type))\n",
      "\n",
      "\n",
      "# ifndef POLYBENCH_STACK_ARRAYS\n",
      "#  define POLYBENCH_1D_ARRAY_DECL(var, type, dim1, ddim1)\t\t\\\n",
      "  type POLYBENCH_1D_F(POLYBENCH_DECL_VAR(var), dim1, ddim1); \\\n",
      "  var = POLYBENCH_ALLOC_1D_ARRAY(POLYBENCH_C99_SELECT(dim1, ddim1), type);\n",
      "#  define POLYBENCH_2D_ARRAY_DECL(var, type, dim1, dim2, ddim1, ddim2)\t\\\n",
      "  type POLYBENCH_2D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, ddim1, ddim2); \\\n",
      "  var = POLYBENCH_ALLOC_2D_ARRAY(POLYBENCH_C99_SELECT(dim1, ddim1), POLYBENCH_C99_SELECT(dim2, ddim2), type);\n",
      "#  define POLYBENCH_3D_ARRAY_DECL(var, type, dim1, dim2, dim3, ddim1, ddim2, ddim3) \\\n",
      "  type POLYBENCH_3D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, dim3, ddim1, ddim2, ddim3); \\\n",
      "  var = POLYBENCH_ALLOC_3D_ARRAY(POLYBENCH_C99_SELECT(dim1, ddim1), POLYBENCH_C99_SELECT(dim2, ddim2), POLYBENCH_C99_SELECT(dim3, ddim3), type);\n",
      "#  define POLYBENCH_4D_ARRAY_DECL(var, type, dim1, dim2, dim3, dim4, ddim1, ddim2, ddim3, ddim4) \\\n",
      "  type POLYBENCH_4D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, dim3, dim4, ddim1, ddim2, ddim3, ddim4); \\\n",
      "  var = POLYBENCH_ALLOC_4D_ARRAY(POLYBENCH_C99_SELECT(dim1, ddim1), POLYBENCH_C99_SELECT(dim2, ddim2), POLYBENCH_C99_SELECT(dim3, ddim3), POLYBENCH_C99_SELECT(dim4, ddim4), type);\n",
      "#  define POLYBENCH_5D_ARRAY_DECL(var, type, dim1, dim2, dim3, dim4, dim5, ddim1, ddim2, ddim3, ddim4, ddim5) \\\n",
      "  type POLYBENCH_5D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, dim3, dim4, dim5, ddim1, ddim2, ddim3, ddim4, ddim5); \\\n",
      "  var = POLYBENCH_ALLOC_5D_ARRAY(POLYBENCH_C99_SELECT(dim1, ddim1), POLYBENCH_C99_SELECT(dim2, ddim2), POLYBENCH_C99_SELECT(dim3, ddim3), POLYBENCH_C99_SELECT(dim4, ddim4), POLYBENCH_C99_SELECT(dim5, ddim5), type);\n",
      "# else\n",
      "#  define POLYBENCH_1D_ARRAY_DECL(var, type, dim1, ddim1)\t\t\\\n",
      "  type POLYBENCH_1D_F(POLYBENCH_DECL_VAR(var), dim1, ddim1);\n",
      "#  define POLYBENCH_2D_ARRAY_DECL(var, type, dim1, dim2, ddim1, ddim2)\t\\\n",
      "  type POLYBENCH_2D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, ddim1, ddim2);\n",
      "#  define POLYBENCH_3D_ARRAY_DECL(var, type, dim1, dim2, dim3, ddim1, ddim2, ddim3) \\\n",
      "  type POLYBENCH_3D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, dim3, ddim1, ddim2, ddim3);\n",
      "#  define POLYBENCH_4D_ARRAY_DECL(var, type, dim1, dim2, dim3, dim4, ddim1, ddim2, ddim3, ddim4) \\\n",
      "  type POLYBENCH_4D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, dim3, dim4, ddim1, ddim2, ddim3, ddim4);\n",
      "#  define POLYBENCH_5D_ARRAY_DECL(var, type, dim1, dim2, dim3, dim4, dim5, ddim1, ddim2, ddim3, ddim4, ddim5) \\\n",
      "  type POLYBENCH_5D_F(POLYBENCH_DECL_VAR(var), dim1, dim2, dim3, dim4, dim5, ddim1, ddim2, ddim3, ddim4, ddim5);\n",
      "# endif\n",
      "\n",
      "\n",
      "\n",
      "# ifndef POLYBENCH_DUMP_ARRAYS\n",
      "#  define POLYBENCH_DCE_ONLY_CODE    if (argc > 42 && ! strcmp(argv[0], \"\"))\n",
      "# else\n",
      "#  define POLYBENCH_DCE_ONLY_CODE\n",
      "# endif\n",
      "\n",
      "#define POLYBENCH_DUMP_TARGET stderr\n",
      "#define POLYBENCH_DUMP_START    fprintf(POLYBENCH_DUMP_TARGET, \"==BEGIN DUMP_ARRAYS==\\n\")\n",
      "#define POLYBENCH_DUMP_FINISH   fprintf(POLYBENCH_DUMP_TARGET, \"==END   DUMP_ARRAYS==\\n\")\n",
      "#define POLYBENCH_DUMP_BEGIN(s) fprintf(POLYBENCH_DUMP_TARGET, \"begin dump: %s\", s)\n",
      "#define POLYBENCH_DUMP_END(s)   fprintf(POLYBENCH_DUMP_TARGET, \"\\nend   dump: %s\\n\", s)\n",
      "\n",
      "# define polybench_prevent_dce(func)\t\t\\\n",
      "  POLYBENCH_DCE_ONLY_CODE\t\t\t\\\n",
      "  func\n",
      "\n",
      "\n",
      "\n",
      "# define polybench_start_instruments\n",
      "# define polybench_stop_instruments\n",
      "# define polybench_print_instruments\n",
      "\n",
      "\n",
      "\n",
      "# ifdef POLYBENCH_PAPI\n",
      "extern const unsigned int polybench_papi_eventlist[];\n",
      "#  undef polybench_start_instruments\n",
      "#  undef polybench_stop_instruments\n",
      "#  undef polybench_print_instruments\n",
      "#  define polybench_set_papi_thread_report(x)\t\\\n",
      "   polybench_papi_counters_threadid = x;\n",
      "#  define polybench_start_instruments\t\t\t\t\\\n",
      "  polybench_prepare_instruments();\t\t\t\t\\\n",
      "  polybench_papi_init();\t\t\t\t\t\\\n",
      "  int evid;\t\t\t\t\t\t\t\\\n",
      "  for (evid = 0; polybench_papi_eventlist[evid] != 0; evid++)\t\\\n",
      "    {\t\t\t\t\t\t\t\t\\\n",
      "      if (polybench_papi_start_counter(evid))\t\t\t\\\n",
      "\tcontinue;\t\t\t\t\t\t\\\n",
      "\n",
      "#  define polybench_stop_instruments\t\t\\\n",
      "      polybench_papi_stop_counter(evid);\t\\\n",
      "    }\t\t\t\t\t\t\\\n",
      "  polybench_papi_close();\t\t\t\\\n",
      "\n",
      "#  define polybench_print_instruments polybench_papi_print();\n",
      "# endif\n",
      "\n",
      "\n",
      "\n",
      "# if defined(POLYBENCH_TIME) || defined(POLYBENCH_GFLOPS)\n",
      "#  undef polybench_start_instruments\n",
      "#  undef polybench_stop_instruments\n",
      "#  undef polybench_print_instruments\n",
      "#  define polybench_start_instruments polybench_timer_start();\n",
      "#  define polybench_stop_instruments polybench_timer_stop();\n",
      "#  define polybench_print_instruments polybench_timer_print();\n",
      "extern double polybench_program_total_flops;\n",
      "extern void polybench_timer_start();\n",
      "extern void polybench_timer_stop();\n",
      "extern void polybench_timer_print();\n",
      "# endif\n",
      "\n",
      "\n",
      "# ifdef POLYBENCH_PAPI\n",
      "extern int polybench_papi_start_counter(int evid);\n",
      "extern void polybench_papi_stop_counter(int evid);\n",
      "extern void polybench_papi_init();\n",
      "extern void polybench_papi_close();\n",
      "extern void polybench_papi_print();\n",
      "# endif\n",
      "\n",
      "\n",
      "extern void* polybench_alloc_data(unsigned long long int n, int elt_size);\n",
      "extern void polybench_free_data(void* ptr);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "extern void polybench_flush_cache();\n",
      "extern void polybench_prepare_instruments();\n",
      "\n",
      "\n",
      "#endif \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"../benchmark_transpilation/linear-algebra/kernels/2mm/2mm.c\"\n",
    "file_path = \"test.c\"\n",
    "operator_path = \"./dsl_operators.py\"\n",
    "file_content = \"\"\n",
    "python_operators = \"\"\n",
    "with open(operator_path, \"r\") as file:\n",
    "    # Read the file content into a string\n",
    "    python_operators = file.read()\n",
    "# Open the file using the path\n",
    "with open(file_path, \"r\") as file:\n",
    "    # Read the file content into a string\n",
    "    file_content = file.read()\n",
    "\n",
    "# Now `file_content` holds the content of the file as a string\n",
    "    def remove_c_comments(code: str) -> str:\n",
    "        # Remove single-line comments\n",
    "        code = re.sub(r'//.*?\\n', '', code)\n",
    "        # Remove multi-line comments\n",
    "        code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "        return code\n",
    "\n",
    "def prepare_prompt(c_code: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "Task: Your task is to rewrite the given C benchmark code in Python. You need to use only the set of \n",
    "provided functions and constants to achieve this. The rewritten program should be semantically \n",
    "equivalent to the benchmark.\n",
    "#Instructions\n",
    "1. The rewritten program should just be a single return statement of the form return_var = provided_function()\n",
    "2. Do not use for/while loops for rewriting the function\n",
    "3. Inline all the expressions, Do not use intermediate variables\n",
    "4. The rewritten program should only use built-in Python functions and the provided functions and constants\n",
    "\n",
    "----------------------------Defined Functions---------------------------- \n",
    "{python_operators}\n",
    "\n",
    "\n",
    "----------------------------Function to Rewrite----------------------------\n",
    "{c_code}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "print(prepare_prompt(remove_c_comments(file_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from typing import Callable, List\n",
      "\n",
      "def matrix_elemwise_add(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_add(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_add(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "def matrix_elemwise_sub(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_sub(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_sub(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "\n",
      "def matrix_elemwise_mul(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_mul(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_mul(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "\n",
      "def matrix_elemwise_div(\n",
      "    matrix_x: List[List[int]], matrix_y: List[List[int]]\n",
      ") -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\n",
      "        else [\n",
      "            vec_elemwise_div(matrix_x[0], matrix_y[0]),\n",
      "            *matrix_elemwise_div(matrix_x[1:], matrix_y[1:]),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "def matrix_scalar_add(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_add(a, matrix_x[0]), *matrix_scalar_add(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def matrix_scalar_sub(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_sub(a, matrix_x[0]), *matrix_scalar_sub(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def matrix_scalar_mul(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_mul(a, matrix_x[0]), *matrix_scalar_mul(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "\n",
      "def matrix_scalar_div(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [vec_scalar_div(a, matrix_x[0]), *matrix_scalar_div(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def scalar_matrix_div(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [scalar_vec_div(a, matrix_x[0]), *scalar_matrix_div(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def scalar_matrix_sub(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\n",
      "    return (\n",
      "        []\n",
      "        if len(matrix_x) < 1\n",
      "        else [scalar_vec_sub(a, matrix_x[0]), *scalar_matrix_sub(a, matrix_x[1:])]\n",
      "    )\n",
      "\n",
      "def scalar_vec_sub(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(a - x[0]), *scalar_vec_sub(a, x[1:])]\n",
      "\n",
      "\n",
      "def scalar_vec_div(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(a // x[0]), *scalar_vec_div(a, x[1:])]\n",
      "\n",
      "\n",
      "def vec_elemwise_add(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [x[0] + y[0], *vec_elemwise_add(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "def vec_elemwise_sub(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [(x[0] - y[0]), *vec_elemwise_sub(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "def vec_elemwise_mul(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [x[0] * y[0], *vec_elemwise_mul(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "def vec_elemwise_div(x: List[int], y: List[int]) -> List[int]:\n",
      "    return (\n",
      "        []\n",
      "        if len(x) < 1 or not len(x) == len(y)\n",
      "        else [(x[0] // y[0]), *vec_elemwise_div(x[1:], y[1:])]\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "def vec_scalar_add(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [a + x[0], *vec_scalar_add(a, x[1:])]\n",
      "\n",
      "def vec_scalar_sub(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(x[0] - a), *vec_scalar_sub(a, x[1:])]\n",
      "\n",
      "\n",
      "def vec_scalar_mul(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [a * x[0], *vec_scalar_mul(a, x[1:])]\n",
      "\n",
      "\n",
      "def vec_scalar_div(a: int, x: List[int]) -> List[int]:\n",
      "    return [] if len(x) < 1 else [(x[0] // a), *vec_scalar_div(a, x[1:])]\n",
      "\n",
      "NI = 1024\n",
      "NJ = 1024\n",
      "NK = 1024\n",
      "NL = 1024\n",
      "\n",
      "def kernel_2mm(ni: int, nj: int, nk: int, nl: int, alpha: float, beta: float, A: List[List[float]], B: List[List[float]], C: List[List[float]], D: List[List[float]]) -> List[List[float]]:\n",
      "    tmp = [[sum(alpha * A[i][k] * B[k][j] for k in range(nk)) for j in range(nj)] for i in range(ni)]\n",
      "    return [[sum(tmp[i][k] * C[k][j] for k in range(nj)) + beta * D[i][j] for j in range(nl)] for i in range(ni)]\n",
      "\n",
      "\n",
      "alpha = 1.5\n",
      "beta = 1.2\n",
      "A = [[(i * j + 1) % NI / NI for j in range(NK)] for i in range(NI)]\n",
      "B = [[i * (j + 1) % NJ / NJ for j in range(NJ)] for i in range(NK)]\n",
      "C = [[(i * (j + 3) + 1) % NL / NL for j in range(NL)] for i in range(NJ)]\n",
      "D = [[i * (j + 2) % NK / NK for j in range(NL)] for i in range(NI)]\n",
      "\n",
      "return_var = kernel_2mm(NI, NJ, NK, NL, alpha, beta, A, B, C, D)\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\nfrom typing import Callable, List\\n\\ndef matrix_elemwise_add(\\n    matrix_x: List[List[int]], matrix_y: List[List[int]]\\n) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\\n        else [\\n            vec_elemwise_add(matrix_x[0], matrix_y[0]),\\n            *matrix_elemwise_add(matrix_x[1:], matrix_y[1:]),\\n        ]\\n    )\\n\\ndef matrix_elemwise_sub(\\n    matrix_x: List[List[int]], matrix_y: List[List[int]]\\n) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\\n        else [\\n            vec_elemwise_sub(matrix_x[0], matrix_y[0]),\\n            *matrix_elemwise_sub(matrix_x[1:], matrix_y[1:]),\\n        ]\\n    )\\n\\n\\ndef matrix_elemwise_mul(\\n    matrix_x: List[List[int]], matrix_y: List[List[int]]\\n) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\\n        else [\\n            vec_elemwise_mul(matrix_x[0], matrix_y[0]),\\n            *matrix_elemwise_mul(matrix_x[1:], matrix_y[1:]),\\n        ]\\n    )\\n\\n\\ndef matrix_elemwise_div(\\n    matrix_x: List[List[int]], matrix_y: List[List[int]]\\n) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1 or not len(matrix_x) == len(matrix_y)\\n        else [\\n            vec_elemwise_div(matrix_x[0], matrix_y[0]),\\n            *matrix_elemwise_div(matrix_x[1:], matrix_y[1:]),\\n        ]\\n    )\\n\\ndef matrix_scalar_add(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1\\n        else [vec_scalar_add(a, matrix_x[0]), *matrix_scalar_add(a, matrix_x[1:])]\\n    )\\n\\ndef matrix_scalar_sub(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1\\n        else [vec_scalar_sub(a, matrix_x[0]), *matrix_scalar_sub(a, matrix_x[1:])]\\n    )\\n\\ndef matrix_scalar_mul(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1\\n        else [vec_scalar_mul(a, matrix_x[0]), *matrix_scalar_mul(a, matrix_x[1:])]\\n    )\\n\\n\\ndef matrix_scalar_div(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1\\n        else [vec_scalar_div(a, matrix_x[0]), *matrix_scalar_div(a, matrix_x[1:])]\\n    )\\n\\ndef scalar_matrix_div(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1\\n        else [scalar_vec_div(a, matrix_x[0]), *scalar_matrix_div(a, matrix_x[1:])]\\n    )\\n\\ndef scalar_matrix_sub(a: int, matrix_x: List[List[int]]) -> List[List[int]]:\\n    return (\\n        []\\n        if len(matrix_x) < 1\\n        else [scalar_vec_sub(a, matrix_x[0]), *scalar_matrix_sub(a, matrix_x[1:])]\\n    )\\n\\ndef scalar_vec_sub(a: int, x: List[int]) -> List[int]:\\n    return [] if len(x) < 1 else [(a - x[0]), *scalar_vec_sub(a, x[1:])]\\n\\n\\ndef scalar_vec_div(a: int, x: List[int]) -> List[int]:\\n    return [] if len(x) < 1 else [(a // x[0]), *scalar_vec_div(a, x[1:])]\\n\\n\\ndef vec_elemwise_add(x: List[int], y: List[int]) -> List[int]:\\n    return (\\n        []\\n        if len(x) < 1 or not len(x) == len(y)\\n        else [x[0] + y[0], *vec_elemwise_add(x[1:], y[1:])]\\n    )\\n\\ndef vec_elemwise_sub(x: List[int], y: List[int]) -> List[int]:\\n    return (\\n        []\\n        if len(x) < 1 or not len(x) == len(y)\\n        else [(x[0] - y[0]), *vec_elemwise_sub(x[1:], y[1:])]\\n    )\\n\\ndef vec_elemwise_mul(x: List[int], y: List[int]) -> List[int]:\\n    return (\\n        []\\n        if len(x) < 1 or not len(x) == len(y)\\n        else [x[0] * y[0], *vec_elemwise_mul(x[1:], y[1:])]\\n    )\\n\\ndef vec_elemwise_div(x: List[int], y: List[int]) -> List[int]:\\n    return (\\n        []\\n        if len(x) < 1 or not len(x) == len(y)\\n        else [(x[0] // y[0]), *vec_elemwise_div(x[1:], y[1:])]\\n    )\\n\\n\\n\\ndef vec_scalar_add(a: int, x: List[int]) -> List[int]:\\n    return [] if len(x) < 1 else [a + x[0], *vec_scalar_add(a, x[1:])]\\n\\ndef vec_scalar_sub(a: int, x: List[int]) -> List[int]:\\n    return [] if len(x) < 1 else [(x[0] - a), *vec_scalar_sub(a, x[1:])]\\n\\n\\ndef vec_scalar_mul(a: int, x: List[int]) -> List[int]:\\n    return [] if len(x) < 1 else [a * x[0], *vec_scalar_mul(a, x[1:])]\\n\\n\\ndef vec_scalar_div(a: int, x: List[int]) -> List[int]:\\n    return [] if len(x) < 1 else [(x[0] // a), *vec_scalar_div(a, x[1:])]\\n\\nNI = 1024\\nNJ = 1024\\nNK = 1024\\nNL = 1024\\n\\ndef kernel_2mm(ni: int, nj: int, nk: int, nl: int, alpha: float, beta: float, A: List[List[float]], B: List[List[float]], C: List[List[float]], D: List[List[float]]) -> List[List[float]]:\\n    tmp = [[sum(alpha * A[i][k] * B[k][j] for k in range(nk)) for j in range(nj)] for i in range(ni)]\\n    return [[sum(tmp[i][k] * C[k][j] for k in range(nj)) + beta * D[i][j] for j in range(nl)] for i in range(ni)]\\n\\n\\nalpha = 1.5\\nbeta = 1.2\\nA = [[(i * j + 1) % NI / NI for j in range(NK)] for i in range(NI)]\\nB = [[i * (j + 1) % NJ / NJ for j in range(NJ)] for i in range(NK)]\\nC = [[(i * (j + 3) + 1) % NL / NL for j in range(NL)] for i in range(NJ)]\\nD = [[i * (j + 2) % NK / NK for j in range(NL)] for i in range(NI)]\\n\\nreturn_var = kernel_2mm(NI, NJ, NK, NL, alpha, beta, A, B, C, D)\\n```'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_llm(prompt: str) -> str:\n",
    "    # Call the Gemini API with the given prompt\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "    print(response.text)\n",
    "    return response.text\n",
    "\n",
    "call_llm(prepare_prompt(remove_c_comments(file_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ps_sols(n, source_code, incorrect_ps_sols):\n",
    "    prompt = prepare_prompt(remove_c_comments(source_code))\n",
    "    ps_sols = []\n",
    "    for _ in range(n):\n",
    "        response = call_llm(prompt)\n",
    "        ps_sol = response.text.strip()\n",
    "        if ps_sol not in incorrect_ps_sols:\n",
    "            ps_sols.append(ps_sol)\n",
    "\n",
    "    return ps_sols\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_path = \"./testResult.py\"\n",
    "parse_result = \"\"\n",
    "with open(parse_path, \"r\") as file:\n",
    "    # Read the file content into a string\n",
    "    parse_result = file.read()\n",
    "def remove_comments(python_code):\n",
    "    # Regex pattern to match docstrings (triple quotes)\n",
    "    docstring_pattern = r'(\"\"\"[\\s\\S]*?\"\"\"|\\'\\'\\'[\\s\\S]*?\\'\\'\\')'\n",
    "    \n",
    "    # Regex pattern to match single-line comments, ensuring it's not inside a string\n",
    "    comment_pattern = r'(?<![\"\\'])#.*'\n",
    "\n",
    "    # Remove docstrings\n",
    "    source_no_docstrings = re.sub(docstring_pattern, '', python_code, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove comments\n",
    "    source_no_comments = re.sub(comment_pattern, '', source_no_docstrings)\n",
    "\n",
    "    return source_no_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mypy_type_to_ir_type(mypy_type: Optional[MypyType]) -> Optional[ObjectT]:\n",
    "    \"\"\"Convert mypy type to python type\"\"\"\n",
    "    if mypy_type is None:\n",
    "        # Handle missing type annotation\n",
    "        # Return None or a default type to represent 'Any'\n",
    "            return None  \n",
    "    if isinstance(mypy_type, UnboundType):\n",
    "        if mypy_type.optional:\n",
    "            raise Exception(\"Optional type not supported\")\n",
    "        if mypy_type.name == \"int\":\n",
    "            return Int\n",
    "        if mypy_type.name == \"bool\":\n",
    "            return Bool\n",
    "        if mypy_type.name == \"Any\":\n",
    "            # This means that no types are enforced\n",
    "            return None\n",
    "        elif mypy_type.name == \"List\" and len(mypy_type.args) == 1:\n",
    "            return List[mypy_type_to_ir_type(mypy_type.args[0])]\n",
    "        elif mypy_type.name == \"Callable\":\n",
    "            if len(mypy_type.args) != 2:\n",
    "                raise Exception(\"Callable type must have two arguments\")\n",
    "            if not isinstance(mypy_type.args[0], TypeList):\n",
    "                raise Exception(\"First argument of Callable type must be a list\")\n",
    "            ret_type = mypy_type_to_ir_type(mypy_type.args[1])\n",
    "            arg_types = (mypy_type_to_ir_type(arg) for arg in mypy_type.args[0].items)\n",
    "            return Fn[pyTuple[(ret_type, *arg_types)]]\n",
    "    elif isinstance(mypy_type, Instance):\n",
    "        if mypy_type.type.fullname == \"builtins.int\":\n",
    "            return Int\n",
    "        elif mypy_type.type.fullname == \"builtins.bool\":\n",
    "            return Bool\n",
    "        elif mypy_type.type.fullname == \"builtins.list\":\n",
    "            return List[mypy_type_to_ir_type(mypy_type.args[0])]\n",
    "    elif isinstance(mypy_type, CallableType):\n",
    "        arg_types = (mypy_type_to_ir_type(arg) for arg in mypy_type.arg_types)\n",
    "        ret_type = mypy_type_to_ir_type(mypy_type.ret_type)\n",
    "        return Fn[pyTuple[(ret_type, *arg_types)]]\n",
    "    elif isinstance(mypy_type, AnyType):\n",
    "        return None\n",
    "    raise Exception(f\"Unsupported type {mypy_type}\")\n",
    "\n",
    "def _get_func_def_ir_type(func_def: FuncDef) -> Type[Fn]:\n",
    "    arg_types = [\n",
    "        mypy_type_to_ir_type(arg.type_annotation if arg.type_annotation is not None else None)\n",
    "        for arg in func_def.arguments\n",
    "    ]\n",
    "    # Check if func_def.type and func_def.type.ret_type exist\n",
    "    ret_type_annotation = func_def.type.ret_type if func_def.type and func_def.type.ret_type else None\n",
    "    ret_type = mypy_type_to_ir_type(ret_type_annotation)\n",
    "    return Fn[pyTuple[(ret_type, *arg_types)]]\n",
    "\n",
    "\n",
    "def _get_func_def_arg_names(func_def: FuncDef) -> pyList[str]:\n",
    "    return [arg.variable.name for arg in func_def.arguments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<mypy.nodes.FuncDef object at 0x3855716c0>]\n"
     ]
    }
   ],
   "source": [
    "universal_imports = f\"\"\"\n",
    "    from dsl_operators import *\n",
    "    from typing import Any, Callable, List\n",
    "    \"\"\"\n",
    "full_prog = dedent(remove_comments(dedent(universal_imports) + dedent(parse_result)))\n",
    "def mypy_parse(full_prog, expected_num_funcs):\n",
    "    # Parse the given Python code using mypy\n",
    "    # Return the parsed MypyFile\n",
    "    options = Options()\n",
    "    options.incremental = False  # turn off caching of previously typed results\n",
    "    options.export_types = True\n",
    "    options.show_traceback = True\n",
    "    options.python_version = PYTHON3_VERSION\n",
    "    options.preserve_asts = True\n",
    "    mypy_build = build.build(\n",
    "        sources=[\n",
    "            BuildSource(path=None, module=\"target_code\", text=full_prog),\n",
    "            BuildSource(path=None, module=\"dsl_operators\")\n",
    "        ],\n",
    "        options=options,\n",
    "    )\n",
    "    target_tree: MypyFile = cast(MypyFile, mypy_build.graph[\"target_code\"].tree)\n",
    "    python_dsl_tree: MypyFile = cast(\n",
    "        MypyFile, mypy_build.graph[\"dsl_operators\"].tree\n",
    "    )  \n",
    "    \n",
    "    target_func_defs = [\n",
    "        func_def for func_def in target_tree.defs if isinstance(func_def, FuncDef)\n",
    "    ]\n",
    "\n",
    "    if len(target_func_defs) != expected_num_funcs:\n",
    "        raise Exception(\n",
    "            f\"{expected_num_funcs} function definition expected but found {len(target_func_defs)}\"\n",
    "        )\n",
    "    dsl_func_defs = [\n",
    "        func_def for func_def in python_dsl_tree.defs if isinstance(func_def, FuncDef)\n",
    "    ]\n",
    "    func_sign = {\n",
    "        func_def.name: (\n",
    "            _get_func_def_ir_type(func_def),\n",
    "            _get_func_def_arg_names(func_def),\n",
    "        )\n",
    "        for func_def in [*target_func_defs, *dsl_func_defs]\n",
    "    }\n",
    "    \n",
    "    return target_func_defs, func_sign, mypy_build.types\n",
    "    \n",
    "x, y, z = mypy_parse(parse_result, 1)\n",
    "print(x)\n",
    "# print(y)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mypy_node_to_ir(\n",
    "    node: Node,\n",
    "    func_sign: Dict[str, pyList[Union[Type, type]]],\n",
    "    types: Dict[Node, MypyType],\n",
    "    fn_decls: pyList[FnDeclRecursive],\n",
    "    in_calls: pyList[pyTuple[str, str]],\n",
    ") -> Expr:\n",
    "    def parse_node(node: Node) -> Expr:\n",
    "        print(node)\n",
    "        if isinstance(node, FuncDef) or isinstance(node, LambdaExpr):\n",
    "            if isinstance(node, FuncDef):\n",
    "                func_ir_type, _ = func_sign[node.name]\n",
    "            else:\n",
    "                func_ir_type = mypy_type_to_ir_type(types[node])\n",
    "            arg_ir_types = func_ir_type.argument_types(get_args(func_ir_type))\n",
    "            ret_ir_type = func_ir_type.return_type(get_args(func_ir_type))\n",
    "            variables: pyList[Object] = []\n",
    "            for arg, ir_type in zip(node.arguments, arg_ir_types):\n",
    "                variables.append(create_object(ir_type, arg.variable.name))\n",
    "            return fn_decl_recursive(\n",
    "                node.name,\n",
    "                ret_ir_type,\n",
    "                parse_node(node.body),\n",
    "                *variables,\n",
    "            )\n",
    "        elif isinstance(node, Block):\n",
    "            if len(node.body) == 2:\n",
    "                if not isinstance(node.body[0], AssignmentStmt):\n",
    "                    raise Exception(\n",
    "                        \"If there are two statements, the statement must be an assignment\"\n",
    "                    )\n",
    "                if not isinstance(node.body[1], ReturnStmt):\n",
    "                    raise Exception(\n",
    "                        \"If there are two statements, the second statement must be a return statement\"\n",
    "                    )\n",
    "\n",
    "                first_stmt = cast(AssignmentStmt, node.body[0])\n",
    "                second_stmt = cast(ReturnStmt, node.body[1])\n",
    "                if len(first_stmt.lvalues) != 1:\n",
    "                    raise Exception(\"Only one lvalue supported\")\n",
    "                if first_stmt.lvalues[0].name != second_stmt.expr.name:\n",
    "                    raise Exception(\n",
    "                        \"Return variable must be the same as the variable assigned\"\n",
    "                    )\n",
    "\n",
    "                return parse_node(first_stmt.rvalue)\n",
    "            elif len(node.body) == 1:\n",
    "                return parse_node(node.body[0])\n",
    "            else:\n",
    "                raise Exception(\"Only one or two statements supported\")\n",
    "        elif isinstance(node, ReturnStmt):\n",
    "            return parse_node(node.expr)\n",
    "        elif isinstance(node, CallExpr):\n",
    "            if isinstance(node.callee, MemberExpr):\n",
    "                raise Exception(\"Method calls not supported\")\n",
    "                # mypy_node_to_ir(node.callee, func_sign, types)\n",
    "            elif isinstance(node.callee, NameExpr):\n",
    "                func_name = cast(NameExpr, node.callee).name\n",
    "\n",
    "                # First we check if this function is a python built-in function\n",
    "                if func_name == \"len\":\n",
    "                    if len(node.args) != 1:\n",
    "                        raise Exception(\"len() takes exactly one argument\")\n",
    "                    arg_expr = parse_node(node.args[0])\n",
    "                    if arg_expr.type.is_nested:\n",
    "                        list_func_name = \"matrix_length\"\n",
    "                    else:\n",
    "                        list_func_name = \"list_length\"\n",
    "                    return call(list_func_name, Int, arg_expr).src\n",
    "                \n",
    "                elif func_name == \"list\":\n",
    "                    # Handle the 'list' built-in function\n",
    "                    if len(node.args) == 0:\n",
    "                        # Create an empty list\n",
    "                        # Assuming default element type is Int; adjust as needed\n",
    "                        list_type = List[Int]\n",
    "                        return List.empty(Int).src\n",
    "                    elif len(node.args) == 1:\n",
    "                        # Create a list from an iterable\n",
    "                        arg_expr = parse_node(node.args[0])\n",
    "                        if is_list_type(arg_expr.type):\n",
    "                            # If the argument is already a list, return it\n",
    "                            return arg_expr.src\n",
    "                        else:\n",
    "                            # If the argument is an iterable, handle accordingly\n",
    "                            # For simplicity, raise an exception\n",
    "                            raise Exception(\"Creating a list from non-list iterables is not supported\")\n",
    "                    else:\n",
    "                        raise Exception(\"list() takes at most one argument\")\n",
    "                elif func_name == \"range\":\n",
    "                # Handle range()\n",
    "                    num_args = len(node.args)\n",
    "                    if num_args == 1:\n",
    "                        # range(stop)\n",
    "                        stop_expr = parse_node(node.args[0])\n",
    "                        start_expr = Int(0)\n",
    "                        step_expr = Int(1)\n",
    "                    elif num_args == 2:\n",
    "                        # range(start, stop)\n",
    "                        start_expr = parse_node(node.args[0])\n",
    "                        stop_expr = parse_node(node.args[1])\n",
    "                        step_expr = Int(1)\n",
    "                    elif num_args == 3:\n",
    "                        # range(start, stop, step)\n",
    "                        start_expr = parse_node(node.args[0])\n",
    "                        stop_expr = parse_node(node.args[1])\n",
    "                        stop_expr = parse_node(node.args[2])\n",
    "                    else:\n",
    "                        raise Exception(\"range() takes 1 to 3 arguments\")\n",
    "\n",
    "                    return List(call(\"range_list\", List[Int], start_expr, stop_expr, stop_expr))\n",
    "                \n",
    "                \n",
    "                if func_name not in func_sign.keys():\n",
    "                    raise Exception(f\"Unknown function {func_name}\")\n",
    "\n",
    "                func_ir_type, arg_names = func_sign[func_name]\n",
    "                ret_ir_type = func_ir_type.return_type(get_args(func_ir_type))\n",
    "                arguments_ir_types = func_ir_type.argument_types(get_args(func_ir_type))\n",
    "\n",
    "                # Check number of arguments\n",
    "                if len(node.args) != len(arguments_ir_types):\n",
    "                    raise Exception(\n",
    "                        f\"Incorrect number of arguments. Required {len(func_sign[func_name])} but got {len(node.args)}\"\n",
    "                    )\n",
    "\n",
    "                # Check argument types and make argument objects\n",
    "                arg_exprs: List[Expr] = []\n",
    "                for idx, (arg, expected_ir_type) in enumerate(\n",
    "                    zip(node.args, arguments_ir_types)\n",
    "                ):\n",
    "                    arg_expr = parse_node(arg)\n",
    "                    if arg_expr.type != expected_ir_type:\n",
    "                        raise Exception(\n",
    "                            f\"Expected type {expected_ir_type} but got {arg_expr.type} for {idx}th argument of {func_name}\"\n",
    "                        )\n",
    "\n",
    "                    # If the argument is a function, then we need to define another function for it\n",
    "                    if is_fn_decl_type(arg_expr.type):\n",
    "                        if isinstance(arg, LambdaExpr):\n",
    "                            arg_fn_name = f\"{arg_names[idx]}_{str(uuid.uuid4())[:8]}\"\n",
    "                            arg_expr.set_name(arg_fn_name)\n",
    "                        elif isinstance(arg, NameExpr):\n",
    "                            arg_fn_name = cast(NameExpr, arg).name\n",
    "                        else:\n",
    "                            raise Exception(\n",
    "                                \"Function argument must be a lambda expression or a function name\"\n",
    "                            )\n",
    "                        fn_decls.append(arg_expr)\n",
    "                        in_calls.append((func_name, arg_fn_name))\n",
    "                    arg_exprs.append(arg_expr)\n",
    "\n",
    "                # Check return type\n",
    "                actual_ret_ir_type = mypy_type_to_ir_type(types.get(node))\n",
    "                print(types.get(node))\n",
    "                if actual_ret_ir_type != ret_ir_type:\n",
    "                    raise Exception(\n",
    "                        f\"Expected return type {ret_ir_type} but got {actual_ret_ir_type} for {func_name}\"\n",
    "                    )\n",
    "                return call(func_name, ret_ir_type, *arg_exprs).src\n",
    "        elif isinstance(node, NameExpr):\n",
    "            # Nothing can go wrong with a name expression (which are basically variables)\n",
    "            ir_type = mypy_type_to_ir_type(types[node])\n",
    "            return create_object(ir_type, node.name).src\n",
    "        # TODO: check not\n",
    "        elif isinstance(node, OpExpr):\n",
    "            left = parse_node(node.left)\n",
    "            right = parse_node(node.right)\n",
    "            op = node.op\n",
    "            if left.type is Int and right.type is Int:\n",
    "                if op == \"+\":\n",
    "                    return Add(left, right)\n",
    "                elif op == \"-\":\n",
    "                    return Sub(left, right)\n",
    "                elif op == \"*\":\n",
    "                    return Mul(left, right)\n",
    "                elif op == \"//\":\n",
    "                    return Div(left, right)\n",
    "                elif op == \"%\":\n",
    "                    return Mod(left, right)\n",
    "                else:\n",
    "                    raise Exception(f\"Unsupported operator {op} on integers\")\n",
    "            elif (\n",
    "                is_list_type(left.type)\n",
    "                and not is_nested_list_type(left.type)\n",
    "                and is_list_type(right.type)\n",
    "                and not is_nested_list_type(right.type)\n",
    "            ):\n",
    "                if op == \"+\":\n",
    "                    return call(\"list_concat\", List[Int], left, right)\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                        f\"Unsupported binary operation {op} on types {left.type} and {right.type}\"\n",
    "                    )\n",
    "            elif left.type is Bool and right.type is Bool:\n",
    "                if op == \"and\":\n",
    "                    return And(left, right)\n",
    "                elif op == \"or\":\n",
    "                    return Or(left, right)\n",
    "                else:\n",
    "                    raise Exception(f\"Unsupported operator {op} on booleans\")\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    f\"Unsupported binary operation {op} on types {left.type} and {right.type}\"\n",
    "                )\n",
    "        elif isinstance(node, IntExpr):\n",
    "            return create_object(Int, node.value).src\n",
    "        elif isinstance(node, ListExpr):\n",
    "            node_type = mypy_type_to_ir_type(types[node])\n",
    "            return node_type.empty(get_args(node_type)[0]).src\n",
    "        elif isinstance(node, ConditionalExpr):\n",
    "            return ite(\n",
    "                parse_node(node.cond),\n",
    "                parse_node(node.if_expr),\n",
    "                parse_node(node.else_expr),\n",
    "            ).src\n",
    "        elif isinstance(node, ComparisonExpr):\n",
    "            if len(node.operators) != 1:\n",
    "                raise Exception(\"Multiple operators not supported\")\n",
    "            if len(node.operands) != 2:\n",
    "                raise Exception(\"Operation must be performed on exactly two operands\")\n",
    "            op = node.operators[0]\n",
    "            left_expr = parse_node(node.operands[0])\n",
    "            right_expr = parse_node(node.operands[1])\n",
    "            if op == \"==\":\n",
    "                if left_expr.type != right_expr.type:\n",
    "                    raise Exception(\n",
    "                        f\"Comparison operator {op} only supported on objects of the same type\"\n",
    "                    )\n",
    "                return Eq(left_expr, right_expr)\n",
    "            else:\n",
    "                if left_expr.type is not Int or right_expr.type is not Int:\n",
    "                    raise Exception(\n",
    "                        f\"Comparison operator {op} only supported on integers\"\n",
    "                    )\n",
    "                if op == \">\":\n",
    "                    return Gt(left_expr, right_expr)\n",
    "                elif op == \"<\":\n",
    "                    return Lt(left_expr, right_expr)\n",
    "                elif op == \">=\":\n",
    "                    return Ge(left_expr, right_expr)\n",
    "                elif op == \"<=\":\n",
    "                    return Le(left_expr, right_expr)\n",
    "                elif op == \"!=\":\n",
    "                    return Not(Eq(left_expr, right_expr))\n",
    "                else:\n",
    "                    raise Exception(f\"Unsupported operator {op}\")\n",
    "        elif isinstance(node, IndexExpr):\n",
    "            base_expr = parse_node(node.base)\n",
    "            base_object = create_object(base_expr.type, base_expr)\n",
    "            if isinstance(node.index, SliceExpr):\n",
    "                # Parse begin index\n",
    "                if node.index.begin_index is None:\n",
    "                    begin_index = None\n",
    "                else:\n",
    "                    begin_index = parse_node(node.index.begin_index)\n",
    "\n",
    "                # Parse end index\n",
    "                if node.index.end_index is None:\n",
    "                    end_index = None\n",
    "                else:\n",
    "                    end_index = parse_node(node.index.end_index)\n",
    "\n",
    "                if begin_index is None and end_index is not None:\n",
    "                    return base_object[:end_index].src\n",
    "                elif begin_index is not None and end_index is None:\n",
    "                    return base_object[begin_index:].src\n",
    "                elif begin_index is not None and end_index is not None:\n",
    "                    return base_object[begin_index:end_index].src\n",
    "                else:\n",
    "                    raise Exception(f\"Unsupported slice {node.index}\")\n",
    "            else:\n",
    "                index_expr = parse_node(node.index)\n",
    "                return base_object[index_expr].src\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported node {node}\")\n",
    "\n",
    "    ps_fn_decl = parse_node(node)\n",
    "    fn_decls.append(ps_fn_decl)\n",
    "    print(in_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_solution(solution: str, expected_num_funcs: int) -> None:\n",
    "    universal_imports = f\"\"\"\n",
    "    from dsl_operators import *\n",
    "    from typing import Any, Callable, List\n",
    "    \"\"\"\n",
    "    full_prog = dedent(remove_comments(dedent(universal_imports) + dedent(solution)))\n",
    "    target_func_defs, func_sigs, types = mypy_parse(full_prog, expected_num_funcs)\n",
    "    fn_decls: pyList[FnDeclRecursive] = []\n",
    "    in_calls: pyList[pyTuple[str, str]] = []\n",
    "    for target_func_def in target_func_defs:\n",
    "        mypy_node_to_ir(target_func_def, func_sigs, types, fn_decls, in_calls)\n",
    "    return fn_decls, in_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FuncDef:4(\n",
      "  kernel_2mm\n",
      "  Args(\n",
      "    Var(ni)\n",
      "    Var(nj)\n",
      "    Var(nk)\n",
      "    Var(nl)\n",
      "    Var(alpha)\n",
      "    Var(beta)\n",
      "    Var(tmp)\n",
      "    Var(A)\n",
      "    Var(B)\n",
      "    Var(C)\n",
      "    Var(D))\n",
      "  def (ni: builtins.int, nj: builtins.int, nk: builtins.int, nl: builtins.int, alpha: builtins.int, beta: builtins.int, tmp: builtins.list[builtins.list[builtins.int]], A: builtins.list[builtins.list[builtins.int]], B: builtins.list[builtins.list[builtins.int]], C: builtins.list[builtins.list[builtins.int]], D: builtins.list[builtins.list[builtins.int]]) -> builtins.list[builtins.list[builtins.int]]\n",
      "  Block:12(\n",
      "    AssignmentStmt:12(\n",
      "      NameExpr(return_var* [l])\n",
      "      CallExpr:12(\n",
      "        NameExpr(matrix_elemwise_add [dsl_operators.matrix_elemwise_add])\n",
      "        Args(\n",
      "          CallExpr:12(\n",
      "            NameExpr(matrix_scalar_mul [dsl_operators.matrix_scalar_mul])\n",
      "            Args(\n",
      "              NameExpr(beta [l])\n",
      "              NameExpr(D [l])))\n",
      "          CallExpr:12(\n",
      "            NameExpr(matrix_elemwise_mul [dsl_operators.matrix_elemwise_mul])\n",
      "            Args(\n",
      "              CallExpr:12(\n",
      "                NameExpr(matrix_elemwise_mul [dsl_operators.matrix_elemwise_mul])\n",
      "                Args(\n",
      "                  CallExpr:12(\n",
      "                    NameExpr(matrix_scalar_mul [dsl_operators.matrix_scalar_mul])\n",
      "                    Args(\n",
      "                      NameExpr(alpha [l])\n",
      "                      NameExpr(A [l])))\n",
      "                  NameExpr(B [l])))\n",
      "              NameExpr(C [l]))))))\n",
      "    ReturnStmt:13(\n",
      "      NameExpr(return_var [l]))))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list expected at most 1 argument, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[439], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y)   \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[0;32m----> 8\u001b[0m fn_d, in_calls \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[439], line 3\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(ps_sol)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(ps_sol):\n\u001b[0;32m----> 3\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mps_sol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m (x)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y)   \n",
      "Cell \u001b[0;32mIn[438], line 11\u001b[0m, in \u001b[0;36mcheck_solution\u001b[0;34m(solution, expected_num_funcs)\u001b[0m\n\u001b[1;32m      9\u001b[0m in_calls: pyList[pyTuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_func_def \u001b[38;5;129;01min\u001b[39;00m target_func_defs:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmypy_node_to_ir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_func_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_sigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_decls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_calls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn_decls, in_calls\n",
      "Cell \u001b[0;32mIn[437], line 278\u001b[0m, in \u001b[0;36mmypy_node_to_ir\u001b[0;34m(node, func_sign, types, fn_decls, in_calls)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m ps_fn_decl \u001b[38;5;241m=\u001b[39m \u001b[43mparse_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m fn_decls\u001b[38;5;241m.\u001b[39mappend(ps_fn_decl)\n",
      "Cell \u001b[0;32mIn[437], line 19\u001b[0m, in \u001b[0;36mmypy_node_to_ir.<locals>.parse_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     17\u001b[0m     variables: pyList[Object] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg, ir_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39marguments, arg_ir_types):\n\u001b[0;32m---> 19\u001b[0m         variables\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcreate_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mir_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn_decl_recursive(\n\u001b[1;32m     21\u001b[0m         node\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     22\u001b[0m         ret_ir_type,\n\u001b[1;32m     23\u001b[0m         parse_node(node\u001b[38;5;241m.\u001b[39mbody),\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;241m*\u001b[39mvariables,\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Block):\n",
      "File \u001b[0;32m~/research/LLMtenspiler/metalift/ir.py:702\u001b[0m, in \u001b[0;36mcreate_object\u001b[0;34m(object_type, value)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m object_cls(get_args(contained_types[\u001b[38;5;241m0\u001b[39m]), value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobject_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontained_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_type(cast(Expr, value))\n",
      "\u001b[0;31mTypeError\u001b[0m: list expected at most 1 argument, got 2"
     ]
    }
   ],
   "source": [
    "# from tenspiler.llm.parser import check_solution\n",
    "def parse(ps_sol):\n",
    "    x, y = check_solution(ps_sol, 1)\n",
    "    print (x)\n",
    "    print(y)   \n",
    "    return x, y\n",
    "\n",
    "fn_d, in_calls = parse(parse_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inv_sols_for_ps(n, ps_sol):\n",
    "    prompt = prepare_prompt(remove_c_comments(ps_sol))\n",
    "    ps_sols = []\n",
    "    for _ in range(n):\n",
    "        response = call_llm(prompt)\n",
    "        ps_sol = response.text.strip()\n",
    "        if ps_sol not in incorrect_ps_sols:\n",
    "            ps_sols.append(ps_sol)\n",
    "\n",
    "    return ps_sols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(ps_sol, inv_sol):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set\n",
    "\n",
    "def transpile_code(source_code: str, num_iters: int, n: int) -> str:\n",
    "    incorrect_ps_sols = set()\n",
    "    seen_ps_sols = set()\n",
    "    for _ in range(num_iters):\n",
    "        ps_sols = get_ps_sols(n, source_code, incorrect_ps_sols)\n",
    "        for ps_sol in ps_sols:\n",
    "            if ps_sol in seen_ps_sols:\n",
    "                continue\n",
    "            if not parse(ps_sol):\n",
    "                continue\n",
    "\n",
    "            #start invarient for the PS\n",
    "            seen_inv_sols_for_ps: set[str] = set()\n",
    "            inv_sols: list[str] = get_inv_sols_for_ps(n, ps_sol)\n",
    "            for inv_sol in inv_sols:\n",
    "            # We have processed this INV for this PS before\n",
    "                if inv_sol in seen_inv_sols_for_ps:\n",
    "                    continue\n",
    "                if not parse(inv_sol):\n",
    "                    continue\n",
    "                #verify the INV for the PS\n",
    "                if verify(ps_sol, inv_sol):\n",
    "                    return ps_sol, inv_sol\n",
    "                seen_inv_sols_for_ps.add(inv_sol)\n",
    "\n",
    "            incorrect_ps_sols.add(ps_sol)\n",
    "            seen_ps_sols.add(ps_sol)\n",
    "\n",
    "    return None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_2mm': (FnDeclRecursive:Function  kernel_2mm (matrix_elemwise_add:List List Int (matrix_scalar_mul:List List Int beta D) (matrix_elemwise_mul:List List Int (matrix_elemwise_mul:List List Int (matrix_scalar_mul:List List Int alpha A) B) C)) ni nj nk nl alpha beta tmp A B C D)}\n",
      "\n",
      "####### import statements ########\n",
      "import torch\n",
      "\n",
      "####### kernel code ########\n",
      "\n",
      "def kernel__torch (ni, nj, nk, nl, alpha, beta, tmp, A, B, C, D):\n",
      "    return ((beta) * (D)) + ((((alpha) * (A)) * (B)) * (C))\n",
      "\n",
      "####### glued code ########\n",
      "\n",
      "def kernel__torch_glued (ni, nj, nk, nl, alpha, beta, tmp, A, B, C, D):\n",
      "\n",
      "    return kernel__torch(ni, nj, nk, nl, alpha, beta, tmp, A, B, C, D)\n",
      "\n",
      "\n",
      "####### import statements ########\n",
      "import torch\n",
      "\n",
      "def kernel__torch (ni, nj, nk, nl, alpha, beta, tmp, A, B, C, D):\n",
      "    return ((beta) * (D)) + ((((alpha) * (A)) * (B)) * (C))\n",
      "\n",
      "def kernel__torch_glued (ni, nj, nk, nl, alpha, beta, tmp, A, B, C, D):\n",
      "\n",
      "    return kernel__torch(ni, nj, nk, nl, alpha, beta, tmp, A, B, C, D)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "from metalift.ir import (\n",
    "    Add,\n",
    "    And,\n",
    "    Bool,\n",
    "    Call,\n",
    "    Div,\n",
    "    Eq,\n",
    "    Expr,\n",
    "    FnDecl,\n",
    "    FnDeclRecursive,\n",
    "    Ge,\n",
    "    Gt,\n",
    "    Int,\n",
    "    Ite,\n",
    "    Le,\n",
    ")\n",
    "from metalift.ir import List as mlList\n",
    "from metalift.ir import Lit, Lt, Matrix, Mod, Mul, Not, ObjectT, Or, Sub, Var\n",
    "from tenspiler.codegen.utils import DataType\n",
    "from tenspiler.tenspiler_common import (\n",
    "    MAP_INT_TO_INT,\n",
    "    MATRIX_ELEMWISE_ADD,\n",
    "    MATRIX_ELEMWISE_DIV,\n",
    "    MATRIX_ELEMWISE_MUL,\n",
    "    MATRIX_ELEMWISE_SUB,\n",
    "    MATRIX_SCALAR_ADD,\n",
    "    MATRIX_SCALAR_DIV,\n",
    "    MATRIX_SCALAR_MUL,\n",
    "    MATRIX_SCALAR_SUB,\n",
    "    SCALAR_MATRIX_DIV,\n",
    "    SCALAR_MATRIX_SUB,\n",
    "    SCALAR_VEC_DIV,\n",
    "    SCALAR_VEC_SUB,\n",
    "    VEC_ELEMWISE_ADD,\n",
    "    VEC_ELEMWISE_DIV,\n",
    "    VEC_ELEMWISE_MUL,\n",
    "    VEC_ELEMWISE_SUB,\n",
    "    VEC_SCALAR_ADD,\n",
    "    VEC_SCALAR_DIV,\n",
    "    VEC_SCALAR_MUL,\n",
    "    VEC_SCALAR_SUB,\n",
    ")\n",
    "\n",
    "# Indentation is 4 spaces\n",
    "INDENTATION = \" \" * 4\n",
    "\n",
    "\n",
    "   \n",
    "translations = {\n",
    "    # VEC_ELEMWISE_ADD: lambda processed_args: f\"torch.add({processed_args[0]}, {processed_args[1]})\",\n",
    "    # MATRIX_ELEMWISE_ADD: lambda processed_args: f\"torch.add({processed_args[0]}, {processed_args[1]})\",\n",
    "    # VEC_SCALAR_ADD: lambda processed_args: f\"torch.add({processed_args[0]}, {processed_args[1]})\",\n",
    "    # MATRIX_SCALAR_ADD: lambda processed_args: f\"torch.add({processed_args[0]}, {processed_args[1]})\",\n",
    "    VEC_ELEMWISE_ADD: lambda processed_args: f\"({processed_args[0]}) + ({processed_args[1]})\",\n",
    "    MATRIX_ELEMWISE_ADD: lambda processed_args: f\"({processed_args[0]}) + ({processed_args[1]})\",\n",
    "    VEC_SCALAR_ADD: lambda processed_args: f\"({processed_args[0]}) + ({processed_args[1]})\",\n",
    "    MATRIX_SCALAR_ADD: lambda processed_args: f\"({processed_args[0]}) + ({processed_args[1]})\",\n",
    "    # VEC_ELEMWISE_SUB: lambda processed_args: f\"torch.sub({processed_args[0]}, {processed_args[1]})\",\n",
    "    # MATRIX_ELEMWISE_SUB: lambda processed_args: f\"torch.sub({processed_args[0]}, {processed_args[1]})\",\n",
    "    # SCALAR_VEC_SUB: lambda processed_args: f\"torch.sub({processed_args[0]}, {processed_args[1]})\",\n",
    "    # SCALAR_MATRIX_SUB: lambda processed_args: f\"torch.sub({processed_args[0]}, {processed_args[1]})\",\n",
    "    VEC_ELEMWISE_SUB: lambda processed_args: f\"({processed_args[0]}) - ({processed_args[1]})\",\n",
    "    MATRIX_ELEMWISE_SUB: lambda processed_args: f\"({processed_args[0]}) - ({processed_args[1]})\",\n",
    "    SCALAR_VEC_SUB: lambda processed_args: f\"({processed_args[0]}) - ({processed_args[1]})\",\n",
    "    SCALAR_MATRIX_SUB: lambda processed_args: f\"({processed_args[0]}) - ({processed_args[1]})\",\n",
    "    # VEC_SCALAR_SUB: lambda processed_args: f\"torch.sub({processed_args[1]}, {processed_args[0]})\",\n",
    "    # MATRIX_SCALAR_SUB: lambda processed_args: f\"torch.sub({processed_args[1]}, {processed_args[0]})\",\n",
    "    VEC_SCALAR_SUB: lambda processed_args: f\"({processed_args[1]}) - ({processed_args[0]})\",\n",
    "    MATRIX_SCALAR_SUB: lambda processed_args: f\"({processed_args[1]}) - ({processed_args[0]})\",\n",
    "    # VEC_ELEMWISE_MUL: lambda processed_args: f\"torch.multiply({processed_args[0]}, {processed_args[1]})\",\n",
    "    # MATRIX_ELEMWISE_MUL: lambda processed_args: f\"torch.multiply({processed_args[0]}, {processed_args[1]})\",\n",
    "    # VEC_SCALAR_MUL: lambda processed_args: f\"torch.multiply({processed_args[0]}, {processed_args[1]})\",\n",
    "    # MATRIX_SCALAR_MUL: lambda processed_args: f\"torch.multiply({processed_args[0]}, {processed_args[1]})\",\n",
    "    VEC_ELEMWISE_MUL: lambda processed_args: f\"({processed_args[0]}) * ({processed_args[1]})\",\n",
    "    MATRIX_ELEMWISE_MUL: lambda processed_args: f\"({processed_args[0]}) * ({processed_args[1]})\",\n",
    "    VEC_SCALAR_MUL: lambda processed_args: f\"({processed_args[0]}) * ({processed_args[1]})\",\n",
    "    MATRIX_SCALAR_MUL: lambda processed_args: f\"({processed_args[0]}) * ({processed_args[1]})\",\n",
    "    # VEC_ELEMWISE_DIV: lambda processed_args: f\"torch.divide({processed_args[0]}, {processed_args[1]})\",\n",
    "    # MATRIX_ELEMWISE_DIV: lambda processed_args: f\"torch.divide({processed_args[0]}, {processed_args[1]})\",\n",
    "    # SCALAR_VEC_DIV: lambda processed_args: f\"torch.divide({processed_args[0]}, {processed_args[1]})\",\n",
    "    # SCALAR_MATRIX_DIV: lambda processed_args: f\"torch.divide({processed_args[0]}, {processed_args[1]})\",\n",
    "    VEC_ELEMWISE_DIV: lambda processed_args, is_floor: f\"({processed_args[0]}) // ({processed_args[1]})\"\n",
    "    if is_floor\n",
    "    else f\"({processed_args[0]}) / ({processed_args[1]})\",\n",
    "    MATRIX_ELEMWISE_DIV: lambda processed_args, is_floor: f\"({processed_args[0]}) // ({processed_args[1]})\"\n",
    "    if is_floor\n",
    "    else f\"({processed_args[0]}) / ({processed_args[1]})\",\n",
    "    SCALAR_VEC_DIV: lambda processed_args, is_floor: f\"({processed_args[0]}) // ({processed_args[1]})\"\n",
    "    if is_floor\n",
    "    else f\"({processed_args[0]}) / ({processed_args[1]})\",\n",
    "    SCALAR_MATRIX_DIV: lambda processed_args, is_floor: f\"({processed_args[0]}) // ({processed_args[1]})\"\n",
    "    if is_floor\n",
    "    else f\"({processed_args[0]}) / ({processed_args[1]})\",\n",
    "    # VEC_SCALAR_DIV: lambda processed_args: f\"torch.divide({processed_args[1]}, {processed_args[0]})\",\n",
    "    # MATRIX_SCALAR_DIV: lambda processed_args: f\"torch.divide({processed_args[1]}, {processed_args[0]})\",\n",
    "    VEC_SCALAR_DIV: lambda processed_args, is_floor: f\"({processed_args[1]}) // ({processed_args[0]})\"\n",
    "    if is_floor\n",
    "    else f\"({processed_args[1]}) / ({processed_args[0]})\",\n",
    "    MATRIX_SCALAR_DIV: lambda processed_args, is_floor: f\"({processed_args[1]}) // ({processed_args[0]})\"\n",
    "    if is_floor\n",
    "    else f\"({processed_args[1]}) / ({processed_args[0]})\",\n",
    "    \"matrix_vec_mul\": lambda processed_args: f\"torch.matmul({processed_args[0]}, {processed_args[1]})\",\n",
    "    \"list_eq\": lambda processed_args: f\"torch.all(torch.eq({processed_args[0]}, {processed_args[1]}))\",\n",
    "    \"list_empty\": lambda processed_args: f\"torch.empty(0)\",\n",
    "    \"matrix_empty\": lambda processed_args: f\"torch.empty(0, 0)\",\n",
    "    \"list_get\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}]\",\n",
    "    \"matrix_get\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}]\",\n",
    "    \"list_append\": lambda processed_args: f\"torch.cat([{processed_args[0]}, {processed_args[1]}.unsqueeze(0)], dim=0)\",\n",
    "    \"matrix_append\": lambda processed_args: f\"torch.cat([{processed_args[0]}, {processed_args[1]}.unsqueeze(0)], dim=0)\",\n",
    "    \"list_prepend\": lambda processed_args: f\"torch.cat([{processed_args[1].unsqueeze(0)}, {processed_args[0]}], dim=0)\",\n",
    "    \"matrix_prepand\": lambda processed_args: f\"torch.cat([{processed_args[1].unsqueeze(0)}, {processed_args[0]}], dim=0)\",\n",
    "    \"list_concat\": lambda processed_args: f\"torch.cat([{processed_args[0]}, {processed_args[1]}], dim=0)\",\n",
    "    \"list_tail\": lambda processed_args: f\"{processed_args[0]}[:{processed_args[1]}]\",\n",
    "    \"matrix_tail\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}:]\",\n",
    "    \"list_take\": lambda processed_args: f\"{processed_args[0]}[:{processed_args[1]}]\",\n",
    "    \"matrix_take\": lambda processed_args: f\"{processed_args[0]}[:{processed_args[1]}]\",\n",
    "    \"vec_slice\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}:{processed_args[2]}]\",\n",
    "    \"matrix_row_slice\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}:{processed_args[2]}]\",\n",
    "    \"vec_slice_with_length\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}:{processed_args[1]} + {processed_args[2]}]\",\n",
    "    \"matrix_row_slice_with_length\": lambda processed_args: f\"{processed_args[0]}[{processed_args[1]}:{processed_args[1]} + {processed_args[2]}]\",\n",
    "    \"matrix_col_slice\": lambda processed_args: f\"{processed_args[0]}[:, {processed_args[1]}:{processed_args[2]}]\",\n",
    "    \"matrix_col_slice_with_length\": lambda processed_args: f\"{processed_args[0]}[:, {processed_args[1]}:{processed_args[1]} + {processed_args[2]}]\",\n",
    "    \"list_length\": lambda processed_args: f\"{processed_args[0]}.size(dim=0)\",\n",
    "    \"matrix_length\": lambda processed_args: f\"{processed_args[0]}.size(dim=0)\",\n",
    "    \"matrix_transpose\": lambda processed_args: f\"torch.transpose({processed_args[0]}, 0, 1)\",\n",
    "    \"reduce_max\": lambda processed_args: f\"torch.max({processed_args[0]})\",\n",
    "    \"reduce_sum\": lambda processed_args: f\"torch.sum({processed_args[0]})\",\n",
    "    \"reduce_mul\": lambda processed_args: f\"torch.prod({processed_args[0]})\",\n",
    "    \"integer_sqrt\": lambda processed_args, is_list=False: f\"torch.sqrt(torch.as_tensor({processed_args[0]}))\",\n",
    "    \"integer_exp\": lambda processed_args, is_list=False: f\"torch.exp(torch.as_tensor({processed_args[0]}))\",\n",
    "    # Add: lambda processed_args, is_int: f\"{processed_args[0]} + {processed_args[1]}\" if is_int else f\"torch.add({processed_args[0]}, {processed_args[1]})\",\n",
    "    # Sub: lambda processed_args, is_int: f\"{processed_args[0]} - {processed_args[1]}\" if is_int else f\"torch.sub({processed_args[0]}, {processed_args[1]})\",\n",
    "    # Mul: lambda processed_args, is_int: f\"{processed_args[0]} * {processed_args[1]}\" if is_int else f\"torch.multiply({processed_args[0]}, {processed_args[1]})\",\n",
    "    # Div: lambda processed_args, is_int: f\"{processed_args[0]} // {processed_args[1]}\" if is_int else f\"torch.divide({processed_args[0]}, {processed_args[1]})\",\n",
    "    Add: lambda processed_args, is_int: f\"({processed_args[0]}) + ({processed_args[1]})\",\n",
    "    Sub: lambda processed_args, is_int: f\"({processed_args[0]}) - ({processed_args[1]})\",\n",
    "    Mul: lambda processed_args, is_int: f\"({processed_args[0]}) * ({processed_args[1]})\",\n",
    "    Div: lambda processed_args, is_int: f\"({processed_args[0]}) // ({processed_args[1]})\",\n",
    "    \"float_div\": lambda processed_args: f\"({processed_args[0]}) / ({processed_args[1]})\",\n",
    "    Mod: lambda processed_args, is_int: f\"({processed_args[0]}) % ({processed_args[1]})\",\n",
    "    Eq: lambda processed_args, is_int: f\"{processed_args[0]} == {processed_args[1]}\"\n",
    "    if is_int\n",
    "    else f\"torch.eq({processed_args[0]}, {processed_args[1]})\",\n",
    "    Gt: lambda processed_args, is_int: f\"{processed_args[0]} > {processed_args[1]}\"\n",
    "    if is_int\n",
    "    else f\"torch.greater({processed_args[0]}, {processed_args[1]})\",\n",
    "    Ge: lambda processed_args, is_int: f\"{processed_args[0]} >= {processed_args[1]}\"\n",
    "    if is_int\n",
    "    else f\"torch.greater_equal({processed_args[0]}, {processed_args[1]})\",\n",
    "    Lt: lambda processed_args, is_int: f\"{processed_args[0]} < {processed_args[1]}\"\n",
    "    if is_int\n",
    "    else f\"torch.less({processed_args[0]}, {processed_args[1]})\",\n",
    "    Le: lambda processed_args, is_int: f\"{processed_args[0]} <= {processed_args[1]}\"\n",
    "    if is_int\n",
    "    else f\"torch.less_equal({processed_args[0]}, {processed_args[1]})\",\n",
    "    Not: lambda processed_args, is_prim: f\"not {processed_args[0]}\"\n",
    "    if is_prim\n",
    "    else f\"torch.logical_not({processed_args[0]})\",\n",
    "    And: lambda processed_args, is_prim: f\"({processed_args[0]}) and ({processed_args[1]})\"\n",
    "    if is_prim\n",
    "    else f\"torch.logical_and({processed_args[0]}, {processed_args[1]})\",\n",
    "    Or: lambda processed_args, is_prim: f\"({processed_args[0]}) or ({processed_args[1]})\"\n",
    "    if is_prim\n",
    "    else f\"torch.logical_or({processed_args[0]}, {processed_args[1]})\",\n",
    "}\n",
    "\n",
    "\n",
    "def pytorch_codegen(\n",
    "    ps_fn_decl: Union[FnDecl, FnDeclRecursive],\n",
    "    all_synthesized_fns: Dict[str, Expr],\n",
    "    d_type: DataType = DataType.FLOAT,\n",
    ") -> str:\n",
    "    has_matmul = False\n",
    "\n",
    "    def helper(expr: Any, vars_to_replace: Dict[str, Expr] = {}) -> Tuple[str, ObjectT]:\n",
    "        nonlocal has_matmul\n",
    "        if not isinstance(expr, Expr):\n",
    "            return str(expr), None\n",
    "        if isinstance(expr, Call):\n",
    "            processed_args = [\n",
    "                helper(arg, vars_to_replace)[0] for arg in expr.arguments()\n",
    "            ]\n",
    "            fn_name = expr.name()\n",
    "\n",
    "            if fn_name == \"matrix_vec_mul\":\n",
    "                has_matmul = True\n",
    "\n",
    "            if fn_name.endswith(\"matrix_selection_two_args\"):\n",
    "                for name, fn in all_synthesized_fns.items():\n",
    "                    if name.endswith(\"select_two_args\"):\n",
    "                        select_two_args_fn_decl = fn\n",
    "                if select_two_args_fn_decl is None:\n",
    "                    raise ValueError(\"select_two_args not found\")\n",
    "                select_two_args_body = select_two_args_fn_decl.body()\n",
    "                cond, if_then, if_else = (\n",
    "                    select_two_args_body.c(),\n",
    "                    select_two_args_body.e1(),\n",
    "                    select_two_args_body.e2(),\n",
    "                )\n",
    "                select_args = select_two_args_fn_decl.arguments()[:2]\n",
    "                matrix_args = expr.arguments()[:2]\n",
    "                vars_to_replace: Dict[str, Expr] = {}\n",
    "                for i in range(2):\n",
    "                    vars_to_replace[select_args[i].name()] = matrix_args[i]\n",
    "\n",
    "                cond_res, cond_type = helper(cond, vars_to_replace)\n",
    "                if_then_res = helper(if_then, vars_to_replace)[0]\n",
    "                if_else_res = helper(if_else, vars_to_replace)[0]\n",
    "                res = f\"torch.where({cond_res}, {if_then_res}, {if_else_res})\"\n",
    "                if cond_type == Bool:\n",
    "                    res = f\"torch.where(torch.tensor({cond_res}), {if_then_res}, {if_else_res})\"\n",
    "                return (\n",
    "                    res,\n",
    "                    expr.type,\n",
    "                )\n",
    "            elif fn_name == MAP_INT_TO_INT or fn_name == \"vec_map\":\n",
    "                map_fn_name = all_synthesized_fns[MAP_INT_TO_INT].body().name()\n",
    "                if map_fn_name in {\"integer_sqrt\", \"integer_exp\"}:\n",
    "                    return (\n",
    "                        translations[map_fn_name](processed_args, fn_name == \"vec_map\"),\n",
    "                        expr.type,\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown map function name: {map_fn_name}\")\n",
    "            elif fn_name in translations.keys():\n",
    "                if fn_name in {\n",
    "                    VEC_ELEMWISE_DIV,\n",
    "                    MATRIX_ELEMWISE_DIV,\n",
    "                    SCALAR_VEC_DIV,\n",
    "                    SCALAR_MATRIX_DIV,\n",
    "                    VEC_SCALAR_DIV,\n",
    "                    MATRIX_SCALAR_DIV,\n",
    "                }:\n",
    "                    return (\n",
    "                        translations[fn_name](processed_args, d_type != DataType.FLOAT),\n",
    "                        expr.type,\n",
    "                    )\n",
    "                return translations[fn_name](processed_args), expr.type\n",
    "            elif fn_name in all_synthesized_fns.keys():\n",
    "                return helper(all_synthesized_fns[fn_name].body())\n",
    "\n",
    "            raise Exception(f\"Unknown function name: {fn_name}\")\n",
    "\n",
    "        # Ite expression. Some condition are constants\n",
    "        if isinstance(expr, Ite):\n",
    "            cond = helper(expr.c())[0]\n",
    "\n",
    "            if cond == \"True\":\n",
    "                return helper(expr.e1(), vars_to_replace)\n",
    "            elif cond == \"False\":\n",
    "                return helper(expr.e2(), vars_to_replace)\n",
    "            else:\n",
    "                return (\n",
    "                    f\"{helper(expr.e1(), vars_to_replace)[0]} if {cond} else {helper(expr.e2(), vars_to_replace)[0]}\",\n",
    "                    expr.e1().type,\n",
    "                )\n",
    "\n",
    "        # Arithmetic operations\n",
    "        processed_args = [helper(arg, vars_to_replace) for arg in expr.args]\n",
    "        processed_args_types = [a[1] for a in processed_args]\n",
    "        processed_args = [a[0] for a in processed_args]\n",
    "        if any(isinstance(expr, cls) for cls in [Add, Sub, Mul, Div, Mod]):\n",
    "            is_arg_type_int = all([a_type is Int for a_type in processed_args_types])\n",
    "            ret_type = (\n",
    "                Int\n",
    "                if is_arg_type_int\n",
    "                else [\n",
    "                    a_type\n",
    "                    for a_type in processed_args_types\n",
    "                    if a_type is not Int and a_type is not None\n",
    "                ][0]\n",
    "            )\n",
    "            if isinstance(expr, Div) and d_type == DataType.FLOAT:\n",
    "                return translations[\"float_div\"](processed_args), ret_type\n",
    "            return translations[type(expr)](processed_args, is_arg_type_int), ret_type\n",
    "\n",
    "        # Relational operations\n",
    "        elif any(isinstance(expr, cls) for cls in [Gt, Ge, Eq, Lt, Le]):\n",
    "            is_arg_type_int = all([a_type is Int for a_type in processed_args_types])\n",
    "            ret_type = Bool if is_arg_type_int else mlList[Bool]\n",
    "            return translations[type(expr)](processed_args, is_arg_type_int), ret_type\n",
    "        elif any(isinstance(expr, cls) for cls in [And, Or, Not]):\n",
    "            is_arg_type_prim = all(\n",
    "                [a_type is Int or a_type is Bool for a_type in processed_args_types]\n",
    "            )\n",
    "            ret_type = Bool if is_arg_type_prim else mlList[Bool]\n",
    "            return translations[type(expr)](processed_args, is_arg_type_prim), ret_type\n",
    "\n",
    "        # Other\n",
    "        elif isinstance(expr, Lit):\n",
    "            return f\"{expr.val()}\", expr.type\n",
    "        elif isinstance(expr, Var):\n",
    "            if expr.name() in vars_to_replace:\n",
    "                return helper(vars_to_replace[expr.name()], vars_to_replace)\n",
    "            return expr.name(), expr.type\n",
    "        return str(expr)\n",
    "\n",
    "    ###############################\n",
    "    # Begins actual code generation\n",
    "    ###############################\n",
    "    import_stmt = \"\"\"\n",
    "####### import statements ########\n",
    "import torch\n",
    "\"\"\"\n",
    "    print(import_stmt)\n",
    "\n",
    "    fn_name = f\"{ps_fn_decl.name()[:-3]}\"\n",
    "    arguments = [arg.name() for arg in ps_fn_decl.arguments()]\n",
    "    arguments_str = \", \".join(arguments)\n",
    "    kernel_name = f\"{fn_name}_torch\"\n",
    "    print(\"####### kernel code ########\")\n",
    "    kernel_fn = f\"\"\"\n",
    "    def {kernel_name} ({arguments_str}):\n",
    "        return {helper(ps_fn_decl.body())[0]}\n",
    "    \"\"\"\n",
    "    kernel_fn = textwrap.dedent(kernel_fn)\n",
    "    print(kernel_fn)\n",
    "\n",
    "    print(\"####### glued code ########\")\n",
    "    glued_name = f\"{fn_name}_torch_glued \"\n",
    "    argument_types = [arg.type for arg in ps_fn_decl.arguments()]\n",
    "\n",
    "    conversions = []\n",
    "    for i in range(len(arguments)):\n",
    "        if argument_types[i] == List[List[Int]] or argument_types[i] == mlList[Int]:\n",
    "            lib_dtype = \"torch.uint8\"\n",
    "            if d_type == DataType.FLOAT:\n",
    "                lib_dtype = \"torch.float32\"\n",
    "\n",
    "            if d_type == DataType.INT32:\n",
    "                lib_dtype = \"torch.int32\"\n",
    "\n",
    "            # matmul require float\n",
    "            if has_matmul:\n",
    "                lib_dtype = \"torch.float32\"\n",
    "\n",
    "            conversions.append(\n",
    "                f\"{arguments[i]} = torch.tensor({arguments[i]}, dtype={lib_dtype})\"\n",
    "            )\n",
    "\n",
    "    arg_processing = f\"\\n{INDENTATION * 2}\".join(conversions)\n",
    "    glued_fn = f\"\"\"\n",
    "    def {glued_name}({arguments_str}):\n",
    "        {arg_processing}\n",
    "        return {kernel_name}({arguments_str})\n",
    "    \"\"\"\n",
    "    glued_fn = textwrap.dedent(glued_fn)\n",
    "    print(glued_fn)\n",
    "\n",
    "    return import_stmt + kernel_fn + glued_fn\n",
    "\n",
    "all_synthesized_fns = {fn.name(): fn for fn in fn_d}\n",
    "\n",
    "print(all_synthesized_fns)\n",
    "print(pytorch_codegen(fn_d[0], all_synthesized_fns, DataType.FLOAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
